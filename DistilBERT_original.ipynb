{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9011ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3374ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/problems.csv\", usecols=[\"description\", \"labels\"])\n",
    "df.head()\n",
    "df['labels'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc954335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.shape\n",
    "df.info()\n",
    "# df.duplicated().sum()\n",
    "df['description'].str.len().plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d00d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "labels_cnt = [l for lab in df['labels'] for l in lab]\n",
    "label_series = pd.Series(labels_cnt).value_counts()\n",
    "print(label_series)\n",
    "\n",
    "print(\"總共有\", label_series.index.nunique(), \"種 labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b2657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel = MultiLabelBinarizer()\n",
    "labels = multilabel.fit_transform(df[\"labels\"]).astype('float32')  # To align label format with model prediction (both are float)\n",
    "texts = df[\"description\"].tolist()\n",
    "# labels\n",
    "# texts[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b356ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "texts_np = np.array(texts)  # 假設 texts 是 list[str]\n",
    "labels_np = np.array(labels)  # 假設 labels 是 np.ndarray [N, C] multi-hot\n",
    "\n",
    "# MIN_VAL_COUNT = 40\n",
    "# for i in range(100):  # 最多嘗試 100 次\n",
    "    \n",
    "#     val_counts = np.sum(y_val, axis=0)\n",
    "#     if np.all(val_counts >= MIN_VAL_COUNT):\n",
    "#         print(f\"Valid split found at iteration {i}\")\n",
    "#         break\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(\n",
    "        texts_np.reshape(-1, 1), labels_np, test_size=0.2\n",
    "    )\n",
    "# 還原回原本格式\n",
    "train_texts = X_train.ravel().tolist()\n",
    "val_texts = X_val.ravel().tolist()\n",
    "train_labels = y_train\n",
    "val_labels = y_val\n",
    "\n",
    "# 統計出現次數\n",
    "train_labels_cnt = np.sum(train_labels, axis=0)\n",
    "val_label_counts = np.sum(val_labels, axis=0)\n",
    "\n",
    "print(\"Train label counts:\", train_labels_cnt)\n",
    "print(\"Val label counts:\", val_label_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(labels[0]),\n",
    "                                                            problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9bb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    label = torch.tensor(self.labels[idx])\n",
    "\n",
    "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'labels': label\n",
    "    }\n",
    "\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88242a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Label Classification Evaluation Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "def multi_labels_metrics(predictions, labels, threshold=0.3):\n",
    "  sigmoid = torch.nn.Sigmoid()\n",
    "  probs = sigmoid(torch.Tensor(predictions))\n",
    "\n",
    "  y_pred = np.zeros(probs.shape)\n",
    "  y_pred[np.where(probs>=threshold)] = 1\n",
    "  y_true = labels\n",
    "\n",
    "  f1 = f1_score(y_true, y_pred, average = 'macro')\n",
    "  roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "  hamming = hamming_loss(y_true, y_pred)\n",
    "\n",
    "  metrics = {\n",
    "      \"roc_auc\": roc_auc,\n",
    "      \"hamming_loss\": hamming,\n",
    "      \"f1\": f1\n",
    "  }\n",
    "\n",
    "  return metrics\n",
    "\n",
    "def compute_metrics(p:EvalPrediction):\n",
    "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "\n",
    "  result = multi_labels_metrics(predictions=preds,\n",
    "                                labels=p.label_ids)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir = './results',\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset = val_dataset,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0eb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert-finetuned-imdb-multi-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"multi-label-binarizer.pkl\", \"wb\") as f:\n",
    "#   pickle.dump(multilabel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78239c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Evaluating...\")\n",
    "preds = trainer.predict(val_dataset).predictions\n",
    "pred_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "label_names = multilabel.classes_\n",
    "print(classification_report(val_labels, pred_binary, target_names=label_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
