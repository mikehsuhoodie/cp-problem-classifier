{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9011ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.12/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.7.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.52.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U accelerate\n",
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3374ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['greedy', 'sorting']\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/problems.csv\", usecols=[\"description\", \"labels\"])\n",
    "df.head()\n",
    "df['labels'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc954335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10912 entries, 0 to 10911\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  10912 non-null  object\n",
      " 1   labels       10912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 170.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.shape\n",
    "df.info()\n",
    "# df.duplicated().sum()\n",
    "df['description'].str.len().plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d00d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math                   3466\n",
      "greedy                 3293\n",
      "data structures        2710\n",
      "dynamic programming    2630\n",
      "graphs                 1950\n",
      "sorting                1488\n",
      "strings                1415\n",
      "binary search          1366\n",
      "trees                  1055\n",
      "number theory           819\n",
      "bit manipulation        785\n",
      "combinatorics           736\n",
      "two pointers            732\n",
      "union find              424\n",
      "geometry                411\n",
      "divide and conquer      334\n",
      "matrices                333\n",
      "shortest path           289\n",
      "game theory             257\n",
      "hashing                 239\n",
      "probabilities           229\n",
      "interactive             210\n",
      "Name: count, dtype: int64\n",
      "總共有 22 種 labels\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "labels_cnt = [l for lab in df['labels'] for l in lab]\n",
    "label_series = pd.Series(labels_cnt).value_counts()\n",
    "print(label_series)\n",
    "\n",
    "print(\"總共有\", label_series.index.nunique(), \"種 labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b2657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "multilabel = MultiLabelBinarizer()\n",
    "labels = multilabel.fit_transform(df[\"labels\"]).astype('float32')  # To align label format with model prediction (both are float)\n",
    "texts = df[\"description\"].tolist()\n",
    "# labels\n",
    "# texts[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, AutoTokenizer\n",
    "from transformers import DistilBertForSequenceClassification, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b356ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label counts: [1093.  628.  584. 2168.  262. 2104.  206.  329. 1560. 2634.  189.  168.\n",
      " 2773.  266.  654.  182.  231. 1190. 1132.  844.  586.  339.]\n",
      "Val label counts: [273. 157. 152. 542.  72. 526.  51.  82. 390. 659.  50.  42. 693.  67.\n",
      " 165.  47.  58. 298. 283. 211. 146.  85.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "texts_np = np.array(texts)  # 假設 texts 是 list[str]\n",
    "labels_np = np.array(labels)  # 假設 labels 是 np.ndarray [N, C] multi-hot\n",
    "\n",
    "# MIN_VAL_COUNT = 40\n",
    "# for i in range(100):  # 最多嘗試 100 次\n",
    "    \n",
    "#     val_counts = np.sum(y_val, axis=0)\n",
    "#     if np.all(val_counts >= MIN_VAL_COUNT):\n",
    "#         print(f\"Valid split found at iteration {i}\")\n",
    "#         break\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split(\n",
    "        texts_np.reshape(-1, 1), labels_np, test_size=0.2\n",
    "    )\n",
    "# 還原回原本格式\n",
    "train_texts = X_train.ravel().tolist()\n",
    "val_texts = X_val.ravel().tolist()\n",
    "train_labels = y_train\n",
    "val_labels = y_val\n",
    "\n",
    "# 統計出現次數\n",
    "train_labels_cnt = np.sum(train_labels, axis=0)\n",
    "val_label_counts = np.sum(val_labels, axis=0)\n",
    "\n",
    "print(\"Train label counts:\", train_labels_cnt)\n",
    "print(\"Val label counts:\", val_label_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a2070dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(labels[0]),\n",
    "                                                            problem_type=\"multi_label_classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9bb38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets build custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    label = torch.tensor(self.labels[idx])\n",
    "\n",
    "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'labels': label\n",
    "    }\n",
    "\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88242a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  3021,  2003,  1037,  3297, 13235,  1999, 11957,  3122,  1012,\n",
       "          4283,  2000,  2010,  6208,  8785, 15636,  2002,  2001,  2583,  2000,\n",
       "          2191,  2438,  2769,  2000,  3857,  1037,  3376,  2160,  1012,  6854,\n",
       "          1010,  2005,  2025,  7079,  3200,  4171,  2006,  2051,  1010,  2457,\n",
       "          2787,  2000, 16385,  3021,  2011,  2437,  2032,  4558,  1037,  2112,\n",
       "          1997,  2010,  3200,  1012,  3021,  1521,  1055,  3200,  2064,  2022,\n",
       "          5159,  2004,  1037, 18309,  3180,  1016,  2078,  1011, 11536, 26572,\n",
       "          7446,  1037,  2692, 17350,  1012,  1012,  1012, 22441,  2078,  1011,\n",
       "          1015, 22441,  2078,  1010, 22441,  2078,  1027,  1037,  2692,  1010,\n",
       "          2007,  3903,  1997,  1996,  3599,  1015,  8316,  1999,  3091,  1012,\n",
       "          2457,  3513,  2005,  9268,  2112,  1997,  2010,  3200,  2024,  2004,\n",
       "          4076,  1024,  1011,  3975,  2296,  3341, 17712, 17712,  1009,  1015,\n",
       "          1010,  1047,  1027,  1014,  1012,  1012,  1012,   102]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6db397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Label Classification Evaluation Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss, roc_curve\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "def find_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        fpr, tpr, th = roc_curve(y_true[:, i], y_probs[:, i])\n",
    "        youdens_j = tpr - fpr\n",
    "        best_th = th[np.argmax(youdens_j)]\n",
    "        thresholds.append(best_th)\n",
    "    print(\"Optimal thresholds:\", thresholds)\n",
    "    return np.array(thresholds)\n",
    "\n",
    "\n",
    "def multi_labels_metrics(predictions, labels):\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    #   probs = sigmoid(torch.Tensor(predictions))\n",
    "    probs = sigmoid(torch.tensor(predictions)).detach().cpu().numpy()\n",
    "\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    # thresholds = np.full(probs.shape[1], 0.3)\n",
    "    \n",
    "    thresholds = np.maximum(find_optimal_thresholds(labels,probs), 0.05)\n",
    "\n",
    "    # y_pred[np.where(probs>=threshold)] = 1\n",
    "    y_pred = (probs >= thresholds).astype(int)\n",
    "    y_true = labels\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average = 'macro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'macro')\n",
    "    hamming = hamming_loss(y_true, y_pred)\n",
    "\n",
    "    metrics = {\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"hamming_loss\": hamming,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def compute_metrics(p:EvalPrediction):\n",
    "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "  \n",
    "  result = multi_labels_metrics(predictions=preds,labels=p.label_ids)\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "beb4378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir = './results',\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset = val_dataset,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "364b9c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5455' max='5455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5455/5455 11:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.297300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.241400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.230700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.207400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.182900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.175100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.159200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5455, training_loss=0.21150065700905132, metrics={'train_runtime': 719.1329, 'train_samples_per_second': 60.67, 'train_steps_per_second': 7.586, 'total_flos': 1445403501419520.0, 'train_loss': 0.21150065700905132, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc88ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='274' max='274' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [274/274 00:18]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal thresholds: [np.float32(0.12036975), np.float32(0.13050556), np.float32(0.06791906), np.float32(0.1771556), np.float32(0.027536802), np.float32(0.21916242), np.float32(0.031269856), np.float32(0.020125106), np.float32(0.19741565), np.float32(0.18488069), np.float32(0.016853461), np.float32(0.08915222), np.float32(0.2966078), np.float32(0.027958767), np.float32(0.23972923), np.float32(0.019208778), np.float32(0.027228631), np.float32(0.076017484), np.float32(0.041665774), np.float32(0.10833892), np.float32(0.07005806), np.float32(0.021570968)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.25740012526512146,\n",
       " 'eval_model_preparation_time': 0.0027,\n",
       " 'eval_roc_auc': 0.7210570106977301,\n",
       " 'eval_hamming_loss': 0.17601680113116527,\n",
       " 'eval_f1': 0.4123475725889586,\n",
       " 'eval_runtime': 18.3728,\n",
       " 'eval_samples_per_second': 118.98,\n",
       " 'eval_steps_per_second': 14.913}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef3f8c",
   "metadata": {},
   "source": [
    "# roc Optimal\n",
    "{'eval_loss': 0.25740012526512146,\n",
    " 'eval_model_preparation_time': 0.0019,\n",
    " 'eval_roc_auc': 0.733163175606855,\n",
    " 'eval_hamming_loss': 0.2093695417117192,\n",
    " 'eval_f1': 0.38514031572779683,\n",
    " 'eval_runtime': 21.0477,\n",
    " 'eval_samples_per_second': 103.859,\n",
    " 'eval_steps_per_second': 13.018}\n",
    "\n",
    "# roc optimal but at least 0.05\n",
    "{'eval_loss': 0.25740012526512146,\n",
    " 'eval_model_preparation_time': 0.0027,\n",
    " 'eval_roc_auc': 0.7210570106977301,\n",
    " 'eval_hamming_loss': 0.17601680113116527,\n",
    " 'eval_f1': 0.4123475725889586,\n",
    " 'eval_runtime': 18.3728,\n",
    " 'eval_samples_per_second': 118.98,\n",
    " 'eval_steps_per_second': 14.913}\n",
    "\n",
    "# 0.3\n",
    "{'eval_loss': 0.25740012526512146,\n",
    " 'eval_model_preparation_time': 0.0017,\n",
    " 'eval_roc_auc': 0.6589950668132519,\n",
    " 'eval_hamming_loss': 0.1096856025950262,\n",
    " 'eval_f1': 0.4090001747729273,\n",
    " 'eval_runtime': 17.6945,\n",
    " 'eval_samples_per_second': 123.542,\n",
    " 'eval_steps_per_second': 15.485}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b0eb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert-finetuned-imdb-multi-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"multi-label-binarizer.pkl\", \"wb\") as f:\n",
    "#   pickle.dump(multilabel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78239c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      binary search       0.50      0.01      0.01       273\n",
      "   bit manipulation       0.60      0.18      0.28       157\n",
      "      combinatorics       0.80      0.05      0.10       152\n",
      "    data structures       0.60      0.20      0.30       542\n",
      " divide and conquer       0.00      0.00      0.00        72\n",
      "dynamic programming       0.45      0.10      0.16       526\n",
      "        game theory       0.71      0.43      0.54        51\n",
      "           geometry       0.65      0.34      0.45        82\n",
      "             graphs       0.68      0.45      0.54       390\n",
      "             greedy       0.52      0.35      0.42       659\n",
      "            hashing       0.00      0.00      0.00        50\n",
      "        interactive       1.00      0.79      0.88        42\n",
      "               math       0.59      0.44      0.50       693\n",
      "           matrices       0.92      0.36      0.52        67\n",
      "      number theory       0.72      0.34      0.46       165\n",
      "      probabilities       0.86      0.13      0.22        47\n",
      "      shortest path       0.00      0.00      0.00        58\n",
      "            sorting       0.47      0.08      0.14       298\n",
      "            strings       0.80      0.61      0.69       283\n",
      "              trees       0.82      0.55      0.66       211\n",
      "       two pointers       0.00      0.00      0.00       146\n",
      "         union find       0.00      0.00      0.00        85\n",
      "\n",
      "          micro avg       0.63      0.27      0.38      5049\n",
      "          macro avg       0.53      0.25      0.31      5049\n",
      "       weighted avg       0.56      0.27      0.34      5049\n",
      "        samples avg       0.49      0.30      0.35      5049\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/cp-problem-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mike/cp-problem-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Evaluating...\")\n",
    "preds = trainer.predict(val_dataset).predictions\n",
    "pred_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "label_names = multilabel.classes_\n",
    "print(classification_report(val_labels, pred_binary, target_names=label_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
