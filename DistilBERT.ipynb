{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9011ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U accelerate\n",
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3374ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John gave Jack a very hard problem. He wrote a...</td>\n",
       "      <td>['math']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Due to the recent popularity of the Deep learn...</td>\n",
       "      <td>['dynamic programming', 'matrices']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill is a famous mathematician in BubbleLand. ...</td>\n",
       "      <td>['greedy', 'sorting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The competitors of Bubble Cup X gathered after...</td>\n",
       "      <td>['shortest path', 'graphs', 'binary search']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John has just bought a new car and is planning...</td>\n",
       "      <td>['dynamic programming']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consider an array A with N elements, all being...</td>\n",
       "      <td>['combinatorics', 'number theory', 'math']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The citizens of BubbleLand are celebrating the...</td>\n",
       "      <td>['dynamic programming', 'geometry']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This story is happening in a town named Bubble...</td>\n",
       "      <td>['trees', 'graphs']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You are given an integer $$$x$$$ of $$$n$$$ di...</td>\n",
       "      <td>['greedy', 'strings']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You are given a Young diagram.  Given diagram ...</td>\n",
       "      <td>['greedy', 'dynamic programming', 'math']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  John gave Jack a very hard problem. He wrote a...   \n",
       "1  Due to the recent popularity of the Deep learn...   \n",
       "2  Bill is a famous mathematician in BubbleLand. ...   \n",
       "3  The competitors of Bubble Cup X gathered after...   \n",
       "4  John has just bought a new car and is planning...   \n",
       "5  Consider an array A with N elements, all being...   \n",
       "6  The citizens of BubbleLand are celebrating the...   \n",
       "7  This story is happening in a town named Bubble...   \n",
       "8  You are given an integer $$$x$$$ of $$$n$$$ di...   \n",
       "9  You are given a Young diagram.  Given diagram ...   \n",
       "\n",
       "                                         labels  \n",
       "0                                      ['math']  \n",
       "1           ['dynamic programming', 'matrices']  \n",
       "2                         ['greedy', 'sorting']  \n",
       "3  ['shortest path', 'graphs', 'binary search']  \n",
       "4                       ['dynamic programming']  \n",
       "5    ['combinatorics', 'number theory', 'math']  \n",
       "6           ['dynamic programming', 'geometry']  \n",
       "7                           ['trees', 'graphs']  \n",
       "8                         ['greedy', 'strings']  \n",
       "9     ['greedy', 'dynamic programming', 'math']  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/problems.csv\", usecols=[\"description\", \"labels\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc954335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10912 entries, 0 to 10911\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  10912 non-null  object\n",
      " 1   labels       10912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 170.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# df.shape\n",
    "df.info()\n",
    "# df.duplicated().sum()\n",
    "# df['description'].str.len().plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d00d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "# labels_cnt = [l for lab in df['labels'] for l in lab]\n",
    "# label_series = pd.Series(labels_cnt).value_counts()\n",
    "# print(label_series)\n",
    "\n",
    "# print(\"總共有\", label_series.index.nunique(), \"種 labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b2657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import torch\n",
    "multilabel = MultiLabelBinarizer()\n",
    "labels = multilabel.fit_transform(df[\"labels\"]).astype('float32') # NumPy ndarray # To align label format with model prediction (both are float)\n",
    "texts = df[\"description\"].tolist()\n",
    "\n",
    "co_matrix = np.dot(labels.T, labels)  # labels: shape (N_samples, N_labels)\n",
    "total = np.sum(co_matrix)\n",
    "# 機率矩陣\n",
    "P_ij = co_matrix / total\n",
    "# 邊際機率 P(i)\n",
    "P_i = np.diag(co_matrix) / total  # shape: (n_labels,)\n",
    "# 外積計算 P(i) * P(j)\n",
    "P_i_P_j = np.outer(P_i, P_i)\n",
    "# PMI 計算，加上小常數避免 log(0)\n",
    "PMI = np.log(P_ij / (P_i_P_j + 1e-10) + 1e-10)\n",
    "np.fill_diagonal(PMI, PMI.max())\n",
    "# Normalize PMI to [0, 1] for soft label weight\n",
    "PMI_norm = (PMI - PMI.min()) / (PMI.max() - PMI.min())\n",
    "PMI_tensor = torch.tensor(PMI_norm, dtype=torch.float32)\n",
    "\n",
    "# soft_labels = torch.matmul(torch.tensor(labels), PMI_tensor)\n",
    "# soft_labels = torch.clamp(soft_labels, 0.0, 1.0)\n",
    "# soft_labels = torch.round(soft_labels * 10) / 10\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# label_names = multilabel.classes_\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(PMI, xticklabels=label_names, yticklabels=label_names, cmap='YlGnBu', annot=False)\n",
    "# plt.title(\"Label Co-occurrence Matrix\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0119630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.7014)\n"
     ]
    }
   ],
   "source": [
    "label_counts = labels.sum(axis=0)\n",
    "k = 100\n",
    "weights = 1.0 / np.log(label_counts + k)\n",
    "weights = weights / np.max(weights)  # normalize to [0, 1]\n",
    "loss_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "# print(multilabel.classes_)\n",
    "# print(label_counts)\n",
    "print(loss_weights.max())\n",
    "print(loss_weights.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d67abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b356ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.8922318  0.59647906 0.5165833  0.8321489  0.7325249  0.7068355\n",
      " 0.7786813  0.685588   0.71685344 1.         0.6454635  0.5578946\n",
      " 0.7105639  0.5049038  0.57523435 0.40439364 0.68423986 1.\n",
      " 0.66521287 0.67514175 0.94502926 0.78884274]\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "texts_np = np.array(texts)  \n",
    "labels_np = np.array(labels)\n",
    "# labels_np = soft_labels.numpy()\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val = iterative_train_test_split( # need  nulti-hot vector should be integer\n",
    "        texts_np.reshape(-1, 1), labels_np, test_size=0.2\n",
    "    )\n",
    "\n",
    "\n",
    "# 還原回原本格式\n",
    "train_texts = X_train.ravel().tolist()\n",
    "val_texts = X_val.ravel().tolist()\n",
    "# train_labels = y_train\n",
    "# val_labels = y_val\n",
    "\n",
    "train_labels = torch.matmul(torch.tensor(y_train), PMI_tensor)\n",
    "val_labels = torch.matmul(torch.tensor(y_val), PMI_tensor)\n",
    "train_labels = torch.clamp(train_labels, 0.0, 1.0)\n",
    "val_labels = torch.clamp(val_labels, 0.0, 1.0)\n",
    "\n",
    "\n",
    "# 統計出現次數（要轉回 numpy）\n",
    "# train_labels_cnt = train_labels.sum(dim=0).numpy()\n",
    "# val_label_counts = val_labels.sum(dim=0).numpy()\n",
    "\n",
    "# print(\"Train label counts:\", train_labels_cnt)\n",
    "# print(\"Val label counts:\", val_label_counts)\n",
    "print(labels_np[0])\n",
    "print(val_labels.numpy()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2070dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertModel\n",
    "\n",
    "class DistilBertWithSoftLabel(nn.Module):\n",
    "    def __init__(self, num_labels, loss_weights):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(reduction='none')  # No reduction \n",
    "        self.loss_weights = loss_weights\n",
    "\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])  # [CLS] token\n",
    "        \n",
    "        if labels is not None: # label is soft_labels\n",
    "            loss_matrix = self.loss_fn(logits, labels)\n",
    "            # loss = loss_matrix.mean()  # or weighted sum\n",
    "            loss_weights = self.loss_weights.to(logits.device)\n",
    "            loss = (loss_matrix * loss_weights).mean()\n",
    "\n",
    "            return {\"logits\": logits, \"loss\": loss}\n",
    "\n",
    "        return {\"logits\": logits}\n",
    "\n",
    "def data_collator(batch):\n",
    "    return {\n",
    "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
    "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
    "        # 'labels': torch.stack([torch.tensor(x['labels'], dtype=torch.float32) for x in batch])\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc9bb38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6928b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(labels[0]),\n",
    "#                                                             problem_type=\"multi_label_classification\")\n",
    "label_counts = labels.sum(axis=0)\n",
    "model = DistilBertWithSoftLabel(num_labels=len(labels[0]),loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "907ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    label = self.labels[idx]\n",
    "    # label = torch.tensor(self.labels[idx])\n",
    "    if not isinstance(label, torch.Tensor):\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "    else:\n",
    "        label = label.detach().clone().float()\n",
    "\n",
    "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'].squeeze(0),\n",
    "        'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        'labels': label\n",
    "    }\n",
    "\n",
    "train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = CustomDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6db397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Label Classification Evaluation Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss, roc_curve\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "def find_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        fpr, tpr, th = roc_curve(y_true[:, i], y_probs[:, i])\n",
    "        youdens_j = tpr - fpr\n",
    "        best_th = th[np.argmax(youdens_j)]\n",
    "        thresholds.append(best_th)\n",
    "    print(\"Optimal thresholds:\", thresholds)\n",
    "    return np.array(thresholds)\n",
    "\n",
    "\n",
    "def find_f1_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    y_true = (y_true >= 0.5).astype(int)\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_th = 0.5\n",
    "        for th in np.linspace(0.05, 0.95, 50):\n",
    "            y_pred_i = (y_probs[:, i] >= th).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], y_pred_i)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_th = th\n",
    "        thresholds.append(best_th)\n",
    "    return np.array(thresholds)\n",
    "\n",
    "\n",
    "def multi_labels_metrics(predictions, labels):\n",
    "  sigmoid = torch.nn.Sigmoid()\n",
    "  # probs = sigmoid(torch.Tensor(predictions))\n",
    "  probs = sigmoid(torch.tensor(predictions)).detach().cpu().numpy()\n",
    "\n",
    "  y_pred = np.zeros(probs.shape)\n",
    "  # y_pred[np.where(probs>=threshold)] = 1\n",
    "  thresholds = np.maximum(find_optimal_thresholds(labels,probs), 0.05)\n",
    "#   thresholds = np.full(probs.shape[1], 0.3)\n",
    "\n",
    "  y_pred = (probs >= thresholds).astype(int)\n",
    "  y_true = labels\n",
    "  \n",
    "  f1 = f1_score(y_true, y_pred, average = 'macro')\n",
    "  roc_auc = roc_auc_score(y_true, probs, average = 'macro')\n",
    "  hamming = hamming_loss(y_true, y_pred)\n",
    "  # # PMI-aware accuracy\n",
    "  # correct = 0\n",
    "  # total = 0\n",
    "  # N, L = y_true.shape # (num_of_samples,num_of_labels)\n",
    "  # pmi_matrix = pmi_matrix.numpy()  # Convert to numpy if it's a tensor\n",
    "\n",
    "  # for sample_idx in range(N):\n",
    "  #   for label_idx in range(L):\n",
    "  #     if y_true[sample_idx][label_idx] == 1:\n",
    "  #       total += 1\n",
    "  #       if y_pred[sample_idx][label_idx] == 1:\n",
    "  #         correct += 1\n",
    "  #       else:\n",
    "  #         related_preds = np.where((y_pred[sample_idx] == 1) & \n",
    "  #                                  (pmi_matrix[label_idx] >= pmi_threshold))[0]\n",
    "  #         if len(related_preds) > 0:\n",
    "  #             correct += 0.5\n",
    "\n",
    "  # pmi_acc = correct / total if total > 0 else 0.0\n",
    "\n",
    "  metrics = {\n",
    "      \"roc_auc\": roc_auc,\n",
    "      \"hamming_loss\": hamming,\n",
    "      \"f1\": f1\n",
    "      # \"pmi_aware_accuracy\": pmi_acc\n",
    "  }\n",
    "  return metrics\n",
    "\n",
    "def compute_metrics(p:EvalPrediction):\n",
    "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "  labels = (p.label_ids > 0.5).astype(int) # p.label_ids\n",
    "  result = multi_labels_metrics(predictions=preds,\n",
    "                                labels=labels)\n",
    "  \n",
    "\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "beb4378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    output_dir = './results',\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=args,\n",
    "                  train_dataset=train_dataset,\n",
    "                  eval_dataset = val_dataset,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364b9c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5460' max='5460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5460/5460 11:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.492300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.459700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.431600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.389100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5460, training_loss=0.44266300690479765, metrics={'train_runtime': 680.4636, 'train_samples_per_second': 64.14, 'train_steps_per_second': 8.024, 'total_flos': 0.0, 'train_loss': 0.44266300690479765, 'epoch': 5.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc88ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='273' max='273' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [273/273 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal thresholds: [np.float32(0.75043064), np.float32(0.72734714), np.float32(0.6868928), np.float32(0.76001805), np.float32(0.7768036), np.float32(0.78052753), np.float32(0.7027774), np.float32(0.5917869), np.float32(0.7343606), np.float32(0.77122116), np.float32(0.70409536), np.float32(0.81710225), np.float32(0.81352794), np.float32(0.6690405), np.float32(0.7421113), np.float32(0.7294288), np.float32(0.6577206), np.float32(0.69850886), np.float32(0.6691999), np.float32(0.81374955), np.float32(0.7118346), np.float32(0.6508711)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5422307252883911,\n",
       " 'eval_model_preparation_time': 0.0062,\n",
       " 'eval_roc_auc': 0.6209105006225866,\n",
       " 'eval_hamming_loss': 0.3794194811143964,\n",
       " 'eval_f1': 0.7055115285615337,\n",
       " 'eval_runtime': 19.9769,\n",
       " 'eval_samples_per_second': 109.276,\n",
       " 'eval_steps_per_second': 13.666}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2eb217",
   "metadata": {},
   "source": [
    "## k=100, Threshold - roc optimal , p.label_ids > 0.8 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_roc_auc': 0.6355803896134508,\n",
    " 'eval_hamming_loss': 0.39180860367301046,\n",
    " 'eval_f1': 0.5670835103814952,\n",
    " 'eval_runtime': 22.0219,\n",
    " 'eval_samples_per_second': 99.129,\n",
    " 'eval_steps_per_second': 12.397,\n",
    " 'epoch': 5.0}\n",
    "\n",
    "## k=100, Threshold = 0.3 , p.label_ids > 0.8 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0041,\n",
    " 'eval_roc_auc': 0.6355803896134508,\n",
    " 'eval_hamming_loss': 0.5140132428268022,\n",
    " 'eval_f1': 0.6445478260151899,\n",
    " 'eval_runtime': 21.2506,\n",
    " 'eval_samples_per_second': 102.727,\n",
    " 'eval_steps_per_second': 12.847}\n",
    "\n",
    "## k=100, Threshold - f1 optimal , p.label_ids > 0.5 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0029,\n",
    " 'eval_roc_auc': 0.6209105006225866,\n",
    " 'eval_hamming_loss': 0.2817015783117478,\n",
    " 'eval_f1': 0.8335942488331942,\n",
    " 'eval_runtime': 21.624,\n",
    " 'eval_samples_per_second': 100.953,\n",
    " 'eval_steps_per_second': 12.625}\n",
    "\n",
    "## k=100, Threshold - roc optimal , p.label_ids > 0.5 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0062,\n",
    " 'eval_roc_auc': 0.6209105006225866,\n",
    " 'eval_hamming_loss': 0.3794194811143964,\n",
    " 'eval_f1': 0.7055115285615337,\n",
    " 'eval_runtime': 19.9769,\n",
    " 'eval_samples_per_second': 109.276,\n",
    " 'eval_steps_per_second': 13.666}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f89716f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary search' 'bit manipulation' 'combinatorics' 'data structures'\n",
      " 'divide and conquer' 'dynamic programming' 'game theory' 'geometry'\n",
      " 'graphs' 'greedy' 'hashing' 'interactive' 'math' 'matrices'\n",
      " 'number theory' 'probabilities' 'shortest path' 'sorting' 'strings'\n",
      " 'trees' 'two pointers' 'union find']\n"
     ]
    }
   ],
   "source": [
    "print(multilabel.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b0eb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert-finetuned-imdb-multi-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffdb6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"multi-label-binarizer.pkl\", \"wb\") as f:\n",
    "#   pickle.dump(multilabel, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78239c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Optimal thresholds: [np.float32(0.88548476), np.float32(0.7720292), np.float32(0.7735398), np.float32(0.792672), np.float32(0.8910758), np.float32(0.8648496), np.float32(0.7028234), np.float32(0.81726617), np.float32(0.84518737), np.float32(0.8566949), np.float32(0.86729276), np.float32(0.7702953), np.float32(0.8123775), np.float32(0.77537405), np.float32(0.7941745), np.float32(0.8243265), np.float32(0.8818463), np.float32(0.81891704), np.float32(0.8309536), np.float32(0.8239958), np.float32(0.8686635), np.float32(0.86369807)]\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "      binary search       0.76      0.81      0.79      1596\n",
      "   bit manipulation       0.76      0.78      0.77      1562\n",
      "      combinatorics       0.82      0.73      0.78      1739\n",
      "    data structures       0.77      0.80      0.79      1607\n",
      " divide and conquer       0.78      0.79      0.79      1632\n",
      "dynamic programming       0.77      0.83      0.80      1609\n",
      "        game theory       0.74      0.77      0.75      1528\n",
      "           geometry       0.71      0.71      0.71      1408\n",
      "             graphs       0.79      0.76      0.78      1612\n",
      "             greedy       0.79      0.87      0.83      1662\n",
      "            hashing       0.77      0.79      0.78      1585\n",
      "        interactive       0.67      0.64      0.66      1322\n",
      "               math       0.80      0.85      0.82      1684\n",
      "           matrices       0.72      0.68      0.70      1468\n",
      "      number theory       0.78      0.76      0.77      1621\n",
      "      probabilities       0.69      0.73      0.71      1364\n",
      "      shortest path       0.75      0.73      0.74      1491\n",
      "            sorting       0.76      0.81      0.78      1577\n",
      "            strings       0.74      0.67      0.70      1445\n",
      "              trees       0.77      0.77      0.77      1566\n",
      "       two pointers       0.77      0.79      0.78      1604\n",
      "         union find       0.79      0.78      0.78      1620\n",
      "\n",
      "          micro avg       0.76      0.77      0.77     34302\n",
      "          macro avg       0.76      0.77      0.76     34302\n",
      "       weighted avg       0.76      0.77      0.76     34302\n",
      "        samples avg       0.73      0.76      0.63     34302\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/cp-problem-classifier/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Evaluating...\")\n",
    "preds = trainer.predict(val_dataset).predictions\n",
    "pred_binary = (preds > 0.5).astype(int)\n",
    "val_labels_binary = (val_labels > 0.5).int().numpy()\n",
    "print(\"\\nClassification Report:\")\n",
    "label_names = multilabel.classes_\n",
    "print(classification_report(val_labels_binary, pred_binary, target_names=label_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
