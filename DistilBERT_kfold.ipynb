{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9011ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U accelerate\n",
    "# !pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e3374ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John gave Jack a very hard problem. He wrote a...</td>\n",
       "      <td>['math']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Due to the recent popularity of the Deep learn...</td>\n",
       "      <td>['dynamic programming', 'matrices']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bill is a famous mathematician in BubbleLand. ...</td>\n",
       "      <td>['greedy', 'sorting']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The competitors of Bubble Cup X gathered after...</td>\n",
       "      <td>['shortest path', 'graphs', 'binary search']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>John has just bought a new car and is planning...</td>\n",
       "      <td>['dynamic programming']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Consider an array A with N elements, all being...</td>\n",
       "      <td>['combinatorics', 'number theory', 'math']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The citizens of BubbleLand are celebrating the...</td>\n",
       "      <td>['dynamic programming', 'geometry']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This story is happening in a town named Bubble...</td>\n",
       "      <td>['trees', 'graphs']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You are given an integer $$$x$$$ of $$$n$$$ di...</td>\n",
       "      <td>['greedy', 'strings']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You are given a Young diagram.  Given diagram ...</td>\n",
       "      <td>['greedy', 'dynamic programming', 'math']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0  John gave Jack a very hard problem. He wrote a...   \n",
       "1  Due to the recent popularity of the Deep learn...   \n",
       "2  Bill is a famous mathematician in BubbleLand. ...   \n",
       "3  The competitors of Bubble Cup X gathered after...   \n",
       "4  John has just bought a new car and is planning...   \n",
       "5  Consider an array A with N elements, all being...   \n",
       "6  The citizens of BubbleLand are celebrating the...   \n",
       "7  This story is happening in a town named Bubble...   \n",
       "8  You are given an integer $$$x$$$ of $$$n$$$ di...   \n",
       "9  You are given a Young diagram.  Given diagram ...   \n",
       "\n",
       "                                         labels  \n",
       "0                                      ['math']  \n",
       "1           ['dynamic programming', 'matrices']  \n",
       "2                         ['greedy', 'sorting']  \n",
       "3  ['shortest path', 'graphs', 'binary search']  \n",
       "4                       ['dynamic programming']  \n",
       "5    ['combinatorics', 'number theory', 'math']  \n",
       "6           ['dynamic programming', 'geometry']  \n",
       "7                           ['trees', 'graphs']  \n",
       "8                         ['greedy', 'strings']  \n",
       "9     ['greedy', 'dynamic programming', 'math']  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./dataset/problems.csv\", usecols=[\"description\", \"labels\"])\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc954335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10912 entries, 0 to 10911\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   description  10912 non-null  object\n",
      " 1   labels       10912 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 170.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# df.shape\n",
    "df.info()\n",
    "# df.duplicated().sum()\n",
    "# df['description'].str.len().plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78d00d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "df['labels'] = df['labels'].apply(ast.literal_eval)\n",
    "# labels_cnt = [l for lab in df['labels'] for l in lab]\n",
    "# label_series = pd.Series(labels_cnt).value_counts()\n",
    "# print(label_series)\n",
    "\n",
    "# print(\"總共有\", label_series.index.nunique(), \"種 labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57b2657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import torch\n",
    "multilabel = MultiLabelBinarizer()\n",
    "labels = multilabel.fit_transform(df[\"labels\"]).astype('float32') # NumPy ndarray # To align label format with model prediction (both are float)\n",
    "texts = df[\"description\"].tolist()\n",
    "\n",
    "co_matrix = np.dot(labels.T, labels)  # labels: shape (N_samples, N_labels)\n",
    "total = np.sum(co_matrix)\n",
    "# 機率矩陣\n",
    "P_ij = co_matrix / total\n",
    "# 邊際機率 P(i)\n",
    "P_i = np.diag(co_matrix) / total  # shape: (n_labels,)\n",
    "# 外積計算 P(i) * P(j)\n",
    "P_i_P_j = np.outer(P_i, P_i)\n",
    "# PMI 計算，加上小常數避免 log(0)\n",
    "PMI = np.log(P_ij / (P_i_P_j + 1e-10) + 1e-10)\n",
    "np.fill_diagonal(PMI, PMI.max())\n",
    "# Normalize PMI to [0, 1] for soft label weight\n",
    "PMI_norm = (PMI - PMI.min()) / (PMI.max() - PMI.min())\n",
    "PMI_tensor = torch.tensor(PMI_norm, dtype=torch.float32)\n",
    "\n",
    "# soft_labels = torch.matmul(torch.tensor(labels), PMI_tensor)\n",
    "# soft_labels = torch.clamp(soft_labels, 0.0, 1.0)\n",
    "# soft_labels = torch.round(soft_labels * 10) / 10\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# label_names = multilabel.classes_\n",
    "# plt.figure(figsize=(12, 10))\n",
    "# sns.heatmap(PMI, xticklabels=label_names, yticklabels=label_names, cmap='YlGnBu', annot=False)\n",
    "# plt.title(\"Label Co-occurrence Matrix\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d67abc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertTokenizerFast\n",
    "from skmultilearn.model_selection import IterativeStratification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b356ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     4     5 ... 10909 10910 10911]\n",
      "[    1     2     3 ... 10886 10891 10900]\n",
      "[    0     1     2 ... 10909 10910 10911]\n",
      "[    5     6    13 ... 10898 10899 10902]\n",
      "[    0     1     2 ... 10909 10910 10911]\n",
      "[    8     9    12 ... 10895 10904 10908]\n",
      "[    0     1     2 ... 10904 10905 10908]\n",
      "[   16    18    21 ... 10909 10910 10911]\n",
      "[    1     2     3 ... 10909 10910 10911]\n",
      "[    0     4    11 ... 10893 10897 10905]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts_np = np.array(texts)  \n",
    "labels_np = np.array(labels)\n",
    "\n",
    "def iterative_kfold_split(X, y, k=5, test_size=0.2):\n",
    "    folds = []\n",
    "    # stratifier = IterativeStratification(n_splits=k, order=2, \n",
    "    #                                      sample_distribution_per_fold=[test_size, 1.0-test_size])\n",
    "    stratifier = IterativeStratification(n_splits=k, order=1)\n",
    "    # train_idx, val_idx = next(stratifier.split(X, y))          \n",
    "    # X_train, y_train = X[train_idx], y[train_idx]\n",
    "    # X_val, y_val = X[val_idx], y[val_idx]\n",
    "    # folds.append((X_train, y_train, X_val, y_val))                      \n",
    "    for train_idx, val_idx in stratifier.split(X, y):\n",
    "        print(train_idx)\n",
    "        print(val_idx)\n",
    "        X_train, y_train = X[train_idx], y[train_idx]\n",
    "        X_val, y_val = X[val_idx], y[val_idx]\n",
    "        folds.append((X_train, y_train, X_val, y_val))\n",
    "    \n",
    "    return folds\n",
    "\n",
    "folds = iterative_kfold_split(texts_np,labels_np,k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0119630b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.7014)\n"
     ]
    }
   ],
   "source": [
    "# calculate loss_weights to deal with dataset imbalance\n",
    "label_counts = labels.sum(axis=0)\n",
    "k = 100\n",
    "weights = 1.0 / np.log(label_counts + k)\n",
    "weights = weights / np.max(weights)  # normalize to [0, 1]\n",
    "loss_weights = torch.tensor(weights, dtype=torch.float32)\n",
    "# print(multilabel.classes_)\n",
    "# print(label_counts)\n",
    "print(loss_weights.max())\n",
    "print(loss_weights.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e877e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertPreTrainedModel, DistilBertModel, DistilBertConfig\n",
    "\n",
    "class DistilBertWithSoftLabel(DistilBertPreTrainedModel):\n",
    "    def __init__(self, config, loss_weights=None):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = DistilBertModel(config)\n",
    "        self.classifier = nn.Linear(config.dim, config.num_labels)\n",
    "        self.loss_weights = loss_weights\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "        if loss_weights is None:\n",
    "            self.loss_weights = torch.ones(config.num_labels)\n",
    "        else:\n",
    "            self.loss_weights = loss_weights\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0])\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_matrix = self.loss_fn(logits, labels)\n",
    "            loss_weights = self.loss_weights.to(logits.device)\n",
    "            loss = (loss_matrix * loss_weights).mean()\n",
    "            \n",
    "            return {\"logits\": logits, \"loss\": loss}\n",
    "        return {\"logits\": logits}\n",
    "    \n",
    "def data_collator(batch):\n",
    "    return {\n",
    "        'input_ids': torch.stack([x['input_ids'] for x in batch]),\n",
    "        'attention_mask': torch.stack([x['attention_mask'] for x in batch]),\n",
    "        # 'labels': torch.stack([torch.tensor(x['labels'], dtype=torch.float32) for x in batch])\n",
    "        'labels': torch.stack([x['labels'] for x in batch])\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6928b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model settings\n",
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(checkpoint)\n",
    "label_counts = labels.sum(axis=0)\n",
    "config = DistilBertConfig.from_pretrained(\"distilbert-base-uncased\", num_labels=len(labels[0]))\n",
    "# model = DistilBertWithSoftLabel(num_labels=len(labels[0]),loss_weights=loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "907ef1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "    self.texts = texts\n",
    "    self.labels = labels\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = str(self.texts[idx])\n",
    "    label = self.labels[idx]\n",
    "    # label = torch.tensor(self.labels[idx])\n",
    "    if not isinstance(label, torch.Tensor):\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "    else:\n",
    "        label = label.detach().clone().float()\n",
    "\n",
    "    encoding = self.tokenizer(text, truncation=True, padding=\"max_length\", max_length=self.max_len, return_tensors='pt')\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoding['input_ids'].squeeze(0),\n",
    "        'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        'token_type_ids': encoding.get('token_type_ids', torch.zeros_like(encoding['input_ids'])).squeeze(0),\n",
    "        'labels': label\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db397ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Label Classification Evaluation Metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, f1_score, hamming_loss, roc_curve\n",
    "from transformers import EvalPrediction\n",
    "import torch\n",
    "\n",
    "\n",
    "def find_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        fpr, tpr, th = roc_curve(y_true[:, i], y_probs[:, i])\n",
    "        youdens_j = tpr - fpr\n",
    "        best_th = th[np.argmax(youdens_j)]\n",
    "        thresholds.append(best_th)\n",
    "    # print(\"Optimal thresholds:\", thresholds)\n",
    "    return np.array(thresholds)\n",
    "\n",
    "\n",
    "def find_f1_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    y_true = (y_true >= 0.5).astype(int)\n",
    "    for i in range(y_true.shape[1]):\n",
    "        best_f1 = 0\n",
    "        best_th = 0.5\n",
    "        for th in np.linspace(0.05, 0.95, 50):\n",
    "            y_pred_i = (y_probs[:, i] >= th).astype(int)\n",
    "            f1 = f1_score(y_true[:, i], y_pred_i)\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                best_th = th\n",
    "        thresholds.append(best_th)\n",
    "    return np.array(thresholds)\n",
    "\n",
    "\n",
    "def multi_labels_metrics(predictions, labels):\n",
    "  sigmoid = torch.nn.Sigmoid()\n",
    "  # probs = sigmoid(torch.Tensor(predictions))\n",
    "  probs = sigmoid(torch.tensor(predictions)).detach().cpu().numpy()\n",
    "\n",
    "  y_pred = np.zeros(probs.shape)\n",
    "#   thresholds = np.maximum(find_optimal_thresholds(labels,probs), 0.05)\n",
    "  thresholds = np.maximum(find_f1_optimal_thresholds(labels,probs), 0.05)\n",
    "#   thresholds = np.full(probs.shape[1], 0.3)\n",
    "\n",
    "  y_pred = (probs >= thresholds).astype(int)\n",
    "  y_true = labels\n",
    "  \n",
    "  f1 = f1_score(y_true, y_pred, average = 'macro')\n",
    "  roc_auc = roc_auc_score(y_true, probs, average = 'macro')\n",
    "  hamming = hamming_loss(y_true, y_pred)\n",
    "\n",
    "  metrics = {\n",
    "      \"roc_auc\": roc_auc,\n",
    "      \"hamming_loss\": hamming,\n",
    "      \"f1\": f1\n",
    "  }\n",
    "  return metrics\n",
    "\n",
    "def compute_metrics(p:EvalPrediction):\n",
    "  preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "  labels = (p.label_ids > 0.5).astype(int) # p.label_ids\n",
    "  result = multi_labels_metrics(predictions=preds,\n",
    "                                labels=labels)\n",
    "  \n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b9c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 8738 train, 2174 val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='732' max='1464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 732/1464 04:42 < 04:43, 2.59 it/s, Epoch 4/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.494600</td>\n",
       "      <td>0.483675</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.270992</td>\n",
       "      <td>0.840980</td>\n",
       "      <td>7.263600</td>\n",
       "      <td>299.300000</td>\n",
       "      <td>6.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.477894</td>\n",
       "      <td>0.671719</td>\n",
       "      <td>0.266476</td>\n",
       "      <td>0.842039</td>\n",
       "      <td>6.844200</td>\n",
       "      <td>317.642000</td>\n",
       "      <td>6.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>0.484116</td>\n",
       "      <td>0.668496</td>\n",
       "      <td>0.270887</td>\n",
       "      <td>0.840966</td>\n",
       "      <td>7.090700</td>\n",
       "      <td>306.599000</td>\n",
       "      <td>6.487000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.436800</td>\n",
       "      <td>0.492211</td>\n",
       "      <td>0.664894</td>\n",
       "      <td>0.269716</td>\n",
       "      <td>0.841264</td>\n",
       "      <td>7.022400</td>\n",
       "      <td>309.581000</td>\n",
       "      <td>6.550000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: 8721 train, 2191 val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='910' max='1456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 910/1456 05:55 < 03:33, 2.55 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.484442</td>\n",
       "      <td>0.648042</td>\n",
       "      <td>0.284138</td>\n",
       "      <td>0.833272</td>\n",
       "      <td>7.037800</td>\n",
       "      <td>311.317000</td>\n",
       "      <td>6.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.480994</td>\n",
       "      <td>0.657409</td>\n",
       "      <td>0.280756</td>\n",
       "      <td>0.834264</td>\n",
       "      <td>7.303900</td>\n",
       "      <td>299.978000</td>\n",
       "      <td>6.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.491401</td>\n",
       "      <td>0.643679</td>\n",
       "      <td>0.277229</td>\n",
       "      <td>0.835448</td>\n",
       "      <td>7.087300</td>\n",
       "      <td>309.145000</td>\n",
       "      <td>6.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.498373</td>\n",
       "      <td>0.653900</td>\n",
       "      <td>0.278640</td>\n",
       "      <td>0.834927</td>\n",
       "      <td>7.110000</td>\n",
       "      <td>308.156000</td>\n",
       "      <td>6.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.516692</td>\n",
       "      <td>0.633753</td>\n",
       "      <td>0.279366</td>\n",
       "      <td>0.834661</td>\n",
       "      <td>7.043200</td>\n",
       "      <td>311.079000</td>\n",
       "      <td>6.531000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: 8752 train, 2160 val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='915' max='1464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 915/1464 05:58 < 03:35, 2.55 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.495400</td>\n",
       "      <td>0.484144</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>0.276010</td>\n",
       "      <td>0.836717</td>\n",
       "      <td>6.736600</td>\n",
       "      <td>320.636000</td>\n",
       "      <td>6.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.478300</td>\n",
       "      <td>0.484936</td>\n",
       "      <td>0.660813</td>\n",
       "      <td>0.275926</td>\n",
       "      <td>0.836567</td>\n",
       "      <td>6.974100</td>\n",
       "      <td>309.717000</td>\n",
       "      <td>6.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.458900</td>\n",
       "      <td>0.484898</td>\n",
       "      <td>0.657302</td>\n",
       "      <td>0.271591</td>\n",
       "      <td>0.838347</td>\n",
       "      <td>7.163200</td>\n",
       "      <td>301.541000</td>\n",
       "      <td>6.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.514471</td>\n",
       "      <td>0.632475</td>\n",
       "      <td>0.277020</td>\n",
       "      <td>0.836722</td>\n",
       "      <td>7.159000</td>\n",
       "      <td>301.719000</td>\n",
       "      <td>6.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.401200</td>\n",
       "      <td>0.516271</td>\n",
       "      <td>0.639324</td>\n",
       "      <td>0.275568</td>\n",
       "      <td>0.837126</td>\n",
       "      <td>7.078400</td>\n",
       "      <td>305.152000</td>\n",
       "      <td>6.357000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='45' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [45/45 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: 8699 train, 2213 val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='910' max='1456' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 910/1456 05:52 < 03:32, 2.57 it/s, Epoch 5/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.489968</td>\n",
       "      <td>0.655400</td>\n",
       "      <td>0.294725</td>\n",
       "      <td>0.824601</td>\n",
       "      <td>6.850600</td>\n",
       "      <td>323.039000</td>\n",
       "      <td>6.861000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.486070</td>\n",
       "      <td>0.676523</td>\n",
       "      <td>0.292774</td>\n",
       "      <td>0.825572</td>\n",
       "      <td>6.955500</td>\n",
       "      <td>318.166000</td>\n",
       "      <td>6.757000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.495718</td>\n",
       "      <td>0.667249</td>\n",
       "      <td>0.290576</td>\n",
       "      <td>0.825850</td>\n",
       "      <td>6.836800</td>\n",
       "      <td>323.687000</td>\n",
       "      <td>6.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.505685</td>\n",
       "      <td>0.663906</td>\n",
       "      <td>0.295855</td>\n",
       "      <td>0.824487</td>\n",
       "      <td>7.016700</td>\n",
       "      <td>315.389000</td>\n",
       "      <td>6.698000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.522492</td>\n",
       "      <td>0.655092</td>\n",
       "      <td>0.295095</td>\n",
       "      <td>0.824443</td>\n",
       "      <td>7.050400</td>\n",
       "      <td>313.881000</td>\n",
       "      <td>6.666000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: 8738 train, 2174 val\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1098' max='1464' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1098/1464 07:07 < 02:22, 2.57 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Hamming Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.484771</td>\n",
       "      <td>0.624101</td>\n",
       "      <td>0.271682</td>\n",
       "      <td>0.841704</td>\n",
       "      <td>7.043600</td>\n",
       "      <td>308.649000</td>\n",
       "      <td>6.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.483876</td>\n",
       "      <td>0.642603</td>\n",
       "      <td>0.269340</td>\n",
       "      <td>0.842553</td>\n",
       "      <td>6.775000</td>\n",
       "      <td>320.886000</td>\n",
       "      <td>6.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.492317</td>\n",
       "      <td>0.640256</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.842244</td>\n",
       "      <td>7.201500</td>\n",
       "      <td>301.882000</td>\n",
       "      <td>6.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.501851</td>\n",
       "      <td>0.641290</td>\n",
       "      <td>0.268713</td>\n",
       "      <td>0.842752</td>\n",
       "      <td>7.401800</td>\n",
       "      <td>293.712000</td>\n",
       "      <td>6.215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.402700</td>\n",
       "      <td>0.517897</td>\n",
       "      <td>0.639427</td>\n",
       "      <td>0.268734</td>\n",
       "      <td>0.842646</td>\n",
       "      <td>7.402500</td>\n",
       "      <td>293.685000</td>\n",
       "      <td>6.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.526435</td>\n",
       "      <td>0.633367</td>\n",
       "      <td>0.269047</td>\n",
       "      <td>0.842573</td>\n",
       "      <td>7.471600</td>\n",
       "      <td>290.969000</td>\n",
       "      <td>6.157000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='46' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 1829.483668088913\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "all_fold_metrics = []\n",
    "\n",
    "for fold_id, (X_train, y_train, X_val, y_val) in enumerate(folds):\n",
    "    train_texts = X_train.ravel().tolist()\n",
    "    val_texts = X_val.ravel().tolist()\n",
    "\n",
    "    train_labels = torch.clamp(torch.matmul(torch.tensor(y_train), PMI_tensor), 0.0, 1.0)\n",
    "    val_labels = torch.clamp(torch.matmul(torch.tensor(y_val), PMI_tensor), 0.0, 1.0)\n",
    "\n",
    "    train_dataset = CustomDataset(train_texts, train_labels, tokenizer)\n",
    "    val_dataset = CustomDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "    model = DistilBertWithSoftLabel(config,num_labels=len(labels[0]),loss_weights=loss_weights)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./results/fold_{fold_id}\",\n",
    "        per_device_train_batch_size=48,          # 提升到 32，RTX 4050 沒問題\n",
    "        per_device_eval_batch_size=48,\n",
    "        num_train_epochs=8,                      # 稍微延長訓練週期，讓稀有 label 能學到\n",
    "        eval_strategy=\"epoch\",             # 每個 epoch 評估一次\n",
    "        save_strategy=\"epoch\",                   # 每個 epoch 存一次模型\n",
    "        save_total_limit=2,                      # 最多保留 2 個 checkpoint\n",
    "        load_best_model_at_end=True,             # 使用 val F1 最佳的模型\n",
    "        metric_for_best_model=\"f1\",              # 根據 F1 分數挑選 best model\n",
    "        greater_is_better=True,\n",
    "        logging_dir=f\"./logs/fold_{fold_id}\",\n",
    "        logging_strategy=\"epoch\",                # 每 epoch log 資訊\n",
    "        report_to=[\"tensorboard\"],\n",
    "        seed=42,\n",
    "        dataloader_num_workers = 4\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    print(f\"Fold {fold_id+1}: {len(train_texts)} train, {len(val_texts)} val\")\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    \n",
    "    all_fold_metrics.append(metrics)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "end = time.time()\n",
    "print(\"Total training time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfd2fb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1: 0.8420\n",
      "Fold 2 F1: 0.8354\n",
      "Fold 3 F1: 0.8383\n",
      "Fold 4 F1: 0.8258\n",
      "Fold 5 F1: 0.8428\n",
      "\n",
      "Average F1 across folds: 0.8369\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(all_fold_metrics):\n",
    "    print(f\"Fold {i+1} F1: {m['eval_f1']:.4f}\")\n",
    "\n",
    "avg_f1 = sum(m['eval_f1'] for m in all_fold_metrics) / len(all_fold_metrics)\n",
    "print(f\"\\nAverage F1 across folds: {avg_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc88ee57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary search' 'bit manipulation' 'combinatorics' 'data structures'\n",
      " 'divide and conquer' 'dynamic programming' 'game theory' 'geometry'\n",
      " 'graphs' 'greedy' 'hashing' 'interactive' 'math' 'matrices'\n",
      " 'number theory' 'probabilities' 'shortest path' 'sorting' 'strings'\n",
      " 'trees' 'two pointers' 'union find']\n"
     ]
    }
   ],
   "source": [
    "print(multilabel.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13843e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./best_model/tokenizer_config.json',\n",
       " './best_model/special_tokens_map.json',\n",
       " './best_model/vocab.txt',\n",
       " './best_model/added_tokens.json',\n",
       " './best_model/tokenizer.json')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "checkpoint_dir = \"./results/fold_0/m364\"\n",
    "output_dir = \"./best_model\"\n",
    "\n",
    "# 1. 載入模型與 tokenizer\n",
    "model = DistilBertWithSoftLabel(config,loss_weights=loss_weights)\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "# 2. 存成部署用格式\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2eb217",
   "metadata": {},
   "source": [
    "## k=100, Threshold - roc optimal , p.label_ids > 0.8 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_roc_auc': 0.6355803896134508,\n",
    " 'eval_hamming_loss': 0.39180860367301046,\n",
    " 'eval_f1': 0.5670835103814952,\n",
    " 'eval_runtime': 22.0219,\n",
    " 'eval_samples_per_second': 99.129,\n",
    " 'eval_steps_per_second': 12.397,\n",
    " 'epoch': 5.0}\n",
    "\n",
    "## k=100, Threshold = 0.3 , p.label_ids > 0.8 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0041,\n",
    " 'eval_roc_auc': 0.6355803896134508,\n",
    " 'eval_hamming_loss': 0.5140132428268022,\n",
    " 'eval_f1': 0.6445478260151899,\n",
    " 'eval_runtime': 21.2506,\n",
    " 'eval_samples_per_second': 102.727,\n",
    " 'eval_steps_per_second': 12.847}\n",
    "\n",
    "## k=100, Threshold - f1 optimal , p.label_ids > 0.5 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0029,\n",
    " 'eval_roc_auc': 0.6209105006225866,\n",
    " 'eval_hamming_loss': 0.2817015783117478,\n",
    " 'eval_f1': 0.8335942488331942,\n",
    " 'eval_runtime': 21.624,\n",
    " 'eval_samples_per_second': 100.953,\n",
    " 'eval_steps_per_second': 12.625}\n",
    "\n",
    "## k=100, Threshold - roc optimal , p.label_ids > 0.5 as P\n",
    "{'eval_loss': 0.5422307252883911,\n",
    " 'eval_model_preparation_time': 0.0062,\n",
    " 'eval_roc_auc': 0.6209105006225866,\n",
    " 'eval_hamming_loss': 0.3794194811143964,\n",
    " 'eval_f1': 0.7055115285615337,\n",
    " 'eval_runtime': 19.9769,\n",
    " 'eval_samples_per_second': 109.276,\n",
    " 'eval_steps_per_second': 13.666}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f89716f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['binary search' 'bit manipulation' 'combinatorics' 'data structures'\n",
      " 'divide and conquer' 'dynamic programming' 'game theory' 'geometry'\n",
      " 'graphs' 'greedy' 'hashing' 'interactive' 'math' 'matrices'\n",
      " 'number theory' 'probabilities' 'shortest path' 'sorting' 'strings'\n",
      " 'trees' 'two pointers' 'union find']\n"
     ]
    }
   ],
   "source": [
    "print(multilabel.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b0eb190",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"distilbert-finetuned-imdb-multi-label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffdb6608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"multi-label-binarizer.pkl\", \"wb\") as f:\n",
    "#   pickle.dump(multilabel, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
